{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def ensure_datetime_format(ds):\n",
    "    if pd.api.types.is_datetime64_any_dtype(ds['time'].dtype):\n",
    "        return ds\n",
    "    else:\n",
    "        ds['time'] = pd.to_datetime(ds['time'].values)\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare GHG historical data\n",
    "ghg_historical = xr.open_dataset('../../data/raw/globalGhgEmissions/CO2_1deg_month_1850-2013.nc')\n",
    "ghg_historical = ghg_historical.rename({'LonDim': 'longitude', 'LatDim': 'latitude', 'Times': 'time'})\n",
    "ghg_historical = ensure_datetime_format(ghg_historical)\n",
    "\n",
    "# Load temperature data for coordinate reference\n",
    "temp_data = xr.open_dataset('../../data/raw/globalTemperature/Land_and_Ocean_LatLong1.nc')\n",
    "ghg_historical = ghg_historical.assign_coords(longitude=temp_data.longitude, latitude=temp_data.latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset for 2014 by extending the last available month of 2013\n",
    "last_month_2013 = ghg_historical.isel(time=-1)\n",
    "gap_year_data = xr.concat([last_month_2013] * 12, dim='time')\n",
    "gap_year_data['time'] = pd.date_range('2014-01', periods=12, freq='MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories for SSP scenarios and output\n",
    "ssp_base_dir = '../../data/raw/globalGhgEmissions'\n",
    "ssp_filenames = [f for f in os.listdir(ssp_base_dir) if f.startswith('CO2_SSP')]\n",
    "processed_dir = '../../data/processed/ssp_combined'\n",
    "os.makedirs(processed_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class 'cftime._cftime.DatetimeNoLeap'> is not convertible to datetime, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m ssp_data \u001b[38;5;241m=\u001b[39m ssp_data\u001b[38;5;241m.\u001b[39massign_coords(longitude\u001b[38;5;241m=\u001b[39mtemp_data\u001b[38;5;241m.\u001b[39mlongitude, latitude\u001b[38;5;241m=\u001b[39mtemp_data\u001b[38;5;241m.\u001b[39mlatitude)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Ensure datetime format is correct for all datasets\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m ssp_data \u001b[38;5;241m=\u001b[39m \u001b[43mensure_datetime_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mssp_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Combine historical, gap year, and SSP data\u001b[39;00m\n\u001b[1;32m     12\u001b[0m combined_ghg \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mconcat([ghg_historical, gap_year_data, ssp_data], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m, in \u001b[0;36mensure_datetime_format\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/climate/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:1099\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         result \u001b[38;5;241m=\u001b[39m _convert_and_box_cache(argc, cache_array)\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43margc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m     result \u001b[38;5;241m=\u001b[39m convert_listlike(np\u001b[38;5;241m.\u001b[39marray([arg]), \u001b[38;5;28mformat\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/climate/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:435\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[0;32m--> 435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     out_unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/climate/lib/python3.12/site-packages/pandas/core/arrays/datetimes.py:2398\u001b[0m, in \u001b[0;36mobjects_to_datetime64\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, allow_object, out_unit)\u001b[0m\n\u001b[1;32m   2395\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[0;32m-> 2398\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2403\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabbrev_to_npy_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_unit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2405\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2408\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m   2409\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[1;32m   2410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, tz_parsed\n",
      "File \u001b[0;32mtslib.pyx:414\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtslib.pyx:596\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtslib.pyx:588\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <class 'cftime._cftime.DatetimeNoLeap'> is not convertible to datetime, at position 0"
     ]
    }
   ],
   "source": [
    "# Prepare and save each SSP scenario\n",
    "for filename in ssp_filenames:\n",
    "    ssp_path = os.path.join(ssp_base_dir, filename)\n",
    "    ssp_data = xr.open_dataset(ssp_path)\n",
    "    ssp_data = ssp_data.rename({'time': 'time', 'latitude': 'latitude', 'longitude': 'longitude'})\n",
    "    ssp_data = ssp_data.assign_coords(longitude=temp_data.longitude, latitude=temp_data.latitude)\n",
    "    \n",
    "    # Ensure datetime format is correct for all datasets\n",
    "    ssp_data = ensure_datetime_format(ssp_data)\n",
    "\n",
    "    # Combine historical, gap year, and SSP data\n",
    "    combined_ghg = xr.concat([ghg_historical, gap_year_data, ssp_data], dim='time')\n",
    "    \n",
    "    # Merge GHG data with temperature data\n",
    "    combined_dataset = xr.merge([temp_data, combined_ghg])\n",
    "\n",
    "    # Save the combined dataset with explicit encoding for time\n",
    "    output_path = os.path.join(processed_dir, filename.replace('.nc', '_combined.nc'))\n",
    "    encoding = {'time': {'units': 'days since 1850-01-01', 'calendar': 'standard'}}\n",
    "    combined_dataset.to_netcdf(output_path, encoding=encoding)\n",
    "    print(f\"Saved combined data for {filename} to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined data for CO2_SSP585_2015_2150.nc to ../../data/processed/ssp_combined/CO2_SSP585_2015_2150_combined.nc\n",
      "Saved combined data for CO2_SSP370_2015_2150.nc to ../../data/processed/ssp_combined/CO2_SSP370_2015_2150_combined.nc\n",
      "Saved combined data for CO2_SSP119_2015_2150.nc to ../../data/processed/ssp_combined/CO2_SSP119_2015_2150_combined.nc\n",
      "Saved combined data for CO2_SSP434_2015_2150.nc to ../../data/processed/ssp_combined/CO2_SSP434_2015_2150_combined.nc\n",
      "Saved combined data for CO2_SSP245_2015_2150.nc to ../../data/processed/ssp_combined/CO2_SSP245_2015_2150_combined.nc\n",
      "Saved combined data for CO2_SSP534_2015_2150.nc to ../../data/processed/ssp_combined/CO2_SSP534_2015_2150_combined.nc\n",
      "Saved combined data for CO2_SSP460_2015_2150.nc to ../../data/processed/ssp_combined/CO2_SSP460_2015_2150_combined.nc\n",
      "Saved combined data for CO2_SSP126_2015_2150.nc to ../../data/processed/ssp_combined/CO2_SSP126_2015_2150_combined.nc\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load GHG historical data and rename coordinates to match the temperature data\n",
    "base_dir = '../../data/raw/globalGhgEmissions'\n",
    "ghg_historical_path = os.path.join(base_dir, 'CO2_1deg_month_1850-2013.nc')\n",
    "ghg_historical = xr.open_dataset(ghg_historical_path)\n",
    "ghg_historical = ghg_historical.rename({'LonDim': 'longitude', 'LatDim': 'latitude', 'Times': 'time'})\n",
    "\n",
    "# Convert 'time' to a continuous integer index starting from 0\n",
    "ghg_historical['time'] = np.arange(len(ghg_historical['time']))\n",
    "\n",
    "# Load temperature data to use as a coordinate reference\n",
    "temp_data_path = '../../data/raw/globalTemperature/Land_and_Ocean_LatLong1.nc'\n",
    "temp_data = xr.open_dataset(temp_data_path)\n",
    "ghg_historical = ghg_historical.assign_coords(longitude=temp_data.longitude, latitude=temp_data.latitude)\n",
    "\n",
    "# Directory for SSP scenarios and output\n",
    "ssp_base_dir = base_dir\n",
    "ssp_filenames = [f for f in os.listdir(ssp_base_dir) if f.startswith('CO2_SSP')]\n",
    "processed_dir = '../../data/processed/ssp_combined'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Process each SSP dataset and assign unique time indices\n",
    "for filename in ssp_filenames:\n",
    "    ssp_path = os.path.join(ssp_base_dir, filename)\n",
    "    ssp_data = xr.open_dataset(ssp_path)\n",
    "    ssp_data = ssp_data.rename({'time': 'time', 'latitude': 'latitude', 'longitude': 'longitude'})\n",
    "\n",
    "    # Assign a continuous index starting after the last index of historical data\n",
    "    ssp_data['time'] = np.arange(len(ghg_historical['time']), len(ghg_historical['time']) + len(ssp_data['time']))\n",
    "\n",
    "    # Combine historical and SSP data along the 'time' dimension without overlap\n",
    "    combined_ghg = xr.concat([ghg_historical, ssp_data], dim='time')\n",
    "\n",
    "    # Combine GHG data with temperature data\n",
    "    combined_dataset = xr.merge([temp_data, combined_ghg])\n",
    "\n",
    "    # Save the combined dataset\n",
    "    output_path = os.path.join(processed_dir, filename.replace('.nc', '_combined.nc'))\n",
    "    combined_dataset.to_netcdf(output_path)\n",
    "    print(f\"Saved combined data for {filename} to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
